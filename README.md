# ğŸ¥Š UFC Fight Outcome Prediction (1994â€“2025)

### UE23CS352A â€“ Machine Learning Mini Project  
**Problem Number:** 74  
**Team Members:**  
- **V C RAMJHITH â€“ PES1UG23CS662**  
- **Tanya Tripathi â€“ PES1UG23CS638**  
**Institution:** PES University, RR Campus, Bengaluru, Karnataka, India  

---

## ğŸ§  Project Overview

This project predicts the outcome of **UFC fights** (Red vs Blue corner) using supervised **machine learning algorithms** trained on UFC fight statistics from **1994 to 2025**.  
Five models were trained and compared to identify the most accurate predictor.

**Models Used:**  
- Logistic Regression  
- Random Forest  
- XGBoost  
- LightGBM  
- CatBoost  

---

## âš™ï¸ How to Run the Project

You can run this project in **Google Colab** or **Jupyter Notebook** using the provided file:
```

UFC_Fight_Outcome_Prediction.ipynb

````

### ğŸ§© Step-by-Step Execution

#### 1ï¸âƒ£ Open in Google Colab
- Upload the notebook to [Google Colab](https://colab.research.google.com/).  
- Ensure runtime type is set to **Python 3**.

#### 2ï¸âƒ£ Download the Dataset
Dataset Source: [UFC Datasets 1994â€“2025 on Kaggle](https://www.kaggle.com/datasets/neelagiriaditya/ufc-datasets-1994-2025)

You can load it in two ways:

##### ğŸ”¹ Option A â€“ Manual Upload
Upload the dataset manually in Colab:
```python
from google.colab import files
uploaded = files.upload()  # Select ufc_dataset.csv
````

##### ğŸ”¹ Option B â€“ Kaggle Import (Recommended)

Use your Kaggle API token (`kaggle.json`) to download the dataset directly:

```bash
!pip install -q kaggle
!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets download -d neelagiriaditya/ufc-datasets-1994-2025
!unzip ufc-datasets-1994-2025.zip
```

Ensure the file name is **`ufc_dataset.csv`** and itâ€™s in the notebookâ€™s working directory.

#### 3ï¸âƒ£ Install Dependencies

If running locally (e.g., Jupyter), install all dependencies:

```bash
pip install -r requirements.txt
```

#### 4ï¸âƒ£ Run All Cells

Execute all cells in order.
The notebook will:

* Load & preprocess data
* Train five models
* Compare metrics (Accuracy, F1 Score, AUC)
* Display confusion matrix, ROC curve, and feature importances

---

## ğŸ“Š Results Summary

| Model               | Accuracy  | F1 Score  | AUC       | Time (s) |
| ------------------- | --------- | --------- | --------- | -------- |
| **Random Forest**   | **0.601** | **0.702** | **0.584** | 3.45     |
| XGBoost             | 0.574     | 0.675     | 0.581     | 6.15     |
| CatBoost            | 0.611     | 0.713     | 0.572     | 43.20    |
| Logistic Regression | 0.507     | 0.560     | 0.519     | 4.63     |
| LightGBM            | 0.541     | 0.649     | 0.509     | 1.08     |

ğŸ† **Best Model:** Random Forest Classifier

* Accuracy â‰ˆ 60 %
* F1 Score â‰ˆ 0.70
* AUC â‰ˆ 0.58

---

## ğŸ§® Data Summary

| Property           | Value                      |
| ------------------ | -------------------------- |
| Records            | 1,477 fights               |
| Raw Columns        | 895                        |
| Processed Features | 1,310                      |
| Target             | Winner (1 = Red, 0 = Blue) |

---

## ğŸ“‚ Repository Structure

```
UFC-Fight-Outcome-Prediction/
â”‚
â”œâ”€â”€ UFC_Fight_Outcome_Prediction.ipynb   # Main notebook
â”œâ”€â”€ ufc_prediction.py                    # Optional Python script version
â”œâ”€â”€ requirements.txt                     # Dependencies list
â”œâ”€â”€ README.md                            # Project documentation
â””â”€â”€ ufc_dataset.csv                      # (Upload or download separately)
```

---

## ğŸ“ˆ Generated Outputs

* âœ… Model comparison summary
* âœ… Confusion matrix heatmap
* âœ… ROC curve visualization
* âœ… Top 15 feature importances
* âœ… Final summary report with metrics

---

## âš ï¸ Challenges

* Slight class imbalance toward Red-corner wins (~59 %).
* High dimensionality (~1,300 features) increased model complexity.
* Missing external factors (strategy, injuries, venue) limited predictive power.

---

## ğŸš€ Future Enhancements

* Apply **stacked ensemble learning** for better generalization.
* Model **fighter performance trends** using LSTM/transformer architectures.
* Integrate **external contextual data** (venue, referee, injury history).
* Use **feature selection** (PCA, mutual information) to reduce complexity.

---

## ğŸ“š References

* [UFC Datasets 1994â€“2025 on Kaggle](https://www.kaggle.com/datasets/neelagiriaditya/ufc-datasets-1994-2025)
* [scikit-learn Documentation](https://scikit-learn.org/stable/)
* [XGBoost](https://xgboost.readthedocs.io/) | [LightGBM](https://lightgbm.readthedocs.io/) | [CatBoost](https://catboost.ai/)

---

## ğŸ‘¥ Authors

| Name               | Roll No       | Contribution                                   |
| ------------------ | ------------- | ---------------------------------------------- |
| **V C RAMJHITH**   | PES1UG23CS662 | Data Preprocessing & Model Implementation      |
| **Tanya Tripathi** | PES1UG23CS638 | Feature Engineering & Evaluation Visualization |

---

## ğŸ Conclusion

The **Random Forest Classifier** achieved the best overall balance of accuracy, interpretability, and runtime.
Although moderate in predictive power, this project demonstrates a complete ML workflow for combat-sports analytics.

> *â€œData may not decide who wins a fight â€” but it shows whoâ€™s more likely to.â€*

````

---

## ğŸ“¦ `requirements.txt`

```text
pandas
numpy
scikit-learn
matplotlib
seaborn
xgboost
lightgbm
catboost
````
