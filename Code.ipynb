{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Objective: Predict the outcome of UFC fights using machine learning algorithms.\n",
        "\n",
        "Dataset: Ultimate UFC Fight Predictor Dataset (March 2010 – December 2024)\n",
        "\n",
        "Features: Fighter statistics, fight outcomes, event details\n",
        "\n",
        "Model:"
      ],
      "metadata": {
        "id": "UYZSiathVK7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost\n",
        "!pip install optuna\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p41kM3S5aLve",
        "outputId": "20f46b4d-80aa-46c1-a45b-17fb7bb225ce"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.12/dist-packages (1.2.8)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.16.5)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.43)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.9.0 optuna-4.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucXI5TEtUjzD",
        "outputId": "02a405fa-9ca8-409e-df25-765fb698d74b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After mapping, class counts:\n",
            " winner\n",
            "1    867\n",
            "0    584\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-10-02 14:55:18,639] A new study created in memory with name: no-name-2f79f8b4-55d0-448f-923f-a21a258f2dc2\n",
            "[I 2025-10-02 14:56:00,171] Trial 0 finished with value: 0.5275862068965518 and parameters: {'n_estimators': 1548, 'max_depth': 7, 'learning_rate': 0.023325652869518473, 'subsample': 0.9290482985314895, 'colsample_bytree': 0.7191139301656968}. Best is trial 0 with value: 0.5275862068965518.\n",
            "[I 2025-10-02 14:56:19,493] Trial 1 finished with value: 0.5379310344827586 and parameters: {'n_estimators': 1538, 'max_depth': 3, 'learning_rate': 0.01899087833383067, 'subsample': 0.8153990803230606, 'colsample_bytree': 0.8196187766728538}. Best is trial 1 with value: 0.5379310344827586.\n",
            "[I 2025-10-02 14:56:33,729] Trial 2 finished with value: 0.5275862068965518 and parameters: {'n_estimators': 967, 'max_depth': 6, 'learning_rate': 0.010570411805161068, 'subsample': 0.9281837771888524, 'colsample_bytree': 0.7456058536107999}. Best is trial 1 with value: 0.5379310344827586.\n",
            "[I 2025-10-02 14:57:03,838] Trial 3 finished with value: 0.5241379310344828 and parameters: {'n_estimators': 1941, 'max_depth': 6, 'learning_rate': 0.08138416158081142, 'subsample': 0.8546147161078055, 'colsample_bytree': 0.764364690724076}. Best is trial 1 with value: 0.5379310344827586.\n",
            "[I 2025-10-02 14:57:38,563] Trial 4 finished with value: 0.5172413793103449 and parameters: {'n_estimators': 1946, 'max_depth': 7, 'learning_rate': 0.018217134536735548, 'subsample': 0.9145961654645633, 'colsample_bytree': 0.9203925900392731}. Best is trial 1 with value: 0.5379310344827586.\n",
            "[I 2025-10-02 14:57:59,438] Trial 5 finished with value: 0.5517241379310345 and parameters: {'n_estimators': 1778, 'max_depth': 3, 'learning_rate': 0.020932415334584273, 'subsample': 0.9727322080269638, 'colsample_bytree': 0.9043858190818516}. Best is trial 5 with value: 0.5517241379310345.\n",
            "[I 2025-10-02 14:58:20,817] Trial 6 finished with value: 0.5206896551724138 and parameters: {'n_estimators': 1236, 'max_depth': 8, 'learning_rate': 0.0841606734481341, 'subsample': 0.6641627530371452, 'colsample_bytree': 0.8867938249025493}. Best is trial 5 with value: 0.5517241379310345.\n"
          ]
        }
      ],
      "source": [
        "# ===============================================\n",
        "# UFC Fight Outcome Prediction - Ultimate Research-Level\n",
        "# ===============================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostClassifier\n",
        "import optuna\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ---------------------------\n",
        "# 1️⃣ Load Dataset\n",
        "# ---------------------------\n",
        "df = pd.read_csv('ufc_fight_data.csv')\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# ---------------------------\n",
        "# 2️⃣ Keep only clear outcomes\n",
        "# ---------------------------\n",
        "df = df[df['winner'].isin(['blue','red'])]\n",
        "df['winner'] = df['winner'].map({'blue':0,'red':1})\n",
        "\n",
        "print(\"After mapping, class counts:\\n\", df['winner'].value_counts())\n",
        "\n",
        "# ---------------------------\n",
        "# 3️⃣ Drop rows with missing essential numeric values\n",
        "# ---------------------------\n",
        "numeric_cols = ['B_Weight','R_Weight','B_Height','R_Height','B_Age','R_Age','BStreak','RStreak']\n",
        "df.dropna(subset=numeric_cols, inplace=True)\n",
        "\n",
        "# ---------------------------\n",
        "# 4️⃣ Feature Engineering\n",
        "# ---------------------------\n",
        "df['weight_diff'] = df['B_Weight'] - df['R_Weight']\n",
        "df['height_diff'] = df['B_Height'] - df['R_Height']\n",
        "df['age_diff'] = df['B_Age'] - df['R_Age']\n",
        "df['streak_diff'] = df['BStreak'] - df['RStreak']\n",
        "\n",
        "df.drop(columns=numeric_cols, inplace=True)\n",
        "\n",
        "# ---------------------------\n",
        "# 5️⃣ Per-round stats differences\n",
        "# ---------------------------\n",
        "rounds = [1,2,3,4,5]\n",
        "stat_types = ['SigStrikes_Landed','SigStrikes_Attempted',\n",
        "              'Takedowns_Landed','Takedowns_Attempted',\n",
        "              'Submissions_Attempted','Grappling_Control_Time']\n",
        "\n",
        "for r in rounds:\n",
        "    for s in stat_types:\n",
        "        b_col = f'B__Round{r}_{s}'\n",
        "        r_col = f'R__Round{r}_{s}'\n",
        "        if b_col in df.columns and r_col in df.columns:\n",
        "            df[f'{s}_diff_R{r}'] = df[b_col] - df[r_col]\n",
        "\n",
        "drop_round_cols = [col for col in df.columns if '__Round' in col]\n",
        "df.drop(columns=drop_round_cols, inplace=True, errors='ignore')\n",
        "\n",
        "# ---------------------------\n",
        "# 6️⃣ Advanced Features\n",
        "# ---------------------------\n",
        "df['B_Strike_Acc'] = df.get('B_SigStrikes_Landed',0) / df.get('B_SigStrikes_Attempted',1)\n",
        "df['R_Strike_Acc'] = df.get('R_SigStrikes_Landed',0) / df.get('R_SigStrikes_Attempted',1)\n",
        "df['strike_acc_diff'] = df['B_Strike_Acc'] - df['R_Strike_Acc']\n",
        "\n",
        "df['B_TD_Acc'] = df.get('B_Takedowns_Landed',0) / df.get('B_Takedowns_Attempted',1)\n",
        "df['R_TD_Acc'] = df.get('R_Takedowns_Landed',0) / df.get('R_Takedowns_Attempted',1)\n",
        "df['td_acc_diff'] = df['B_TD_Acc'] - df['R_TD_Acc']\n",
        "\n",
        "df['recent_streak_diff'] = df.get('BStreak',0) - df.get('RStreak',0)\n",
        "\n",
        "for col in ['B_SigStrikes_Landed','B_SigStrikes_Attempted','R_SigStrikes_Landed','R_SigStrikes_Attempted',\n",
        "            'B_Takedowns_Landed','B_Takedowns_Attempted','R_Takedowns_Landed','R_Takedowns_Attempted']:\n",
        "    if col in df.columns:\n",
        "        df.drop(columns=col, inplace=True)\n",
        "\n",
        "# ---------------------------\n",
        "# 7️⃣ Drop noisy categorical columns\n",
        "# ---------------------------\n",
        "drop_cols = [col for col in df.columns if 'Name' in col]\n",
        "df.drop(columns=drop_cols, inplace=True, errors='ignore')\n",
        "\n",
        "categorical_cols = [col for col in df.columns if df[col].dtype=='object']\n",
        "df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "# ---------------------------\n",
        "# 8️⃣ Features and target\n",
        "# ---------------------------\n",
        "X = df.drop('winner', axis=1)\n",
        "y = df['winner']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
        "\n",
        "# ---------------------------\n",
        "# 9️⃣ Train-Test Split\n",
        "# ---------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# ---------------------------\n",
        "# 🔹 10️⃣ Optuna Hyperparameter Tuning\n",
        "# ---------------------------\n",
        "def tune_xgb(trial):\n",
        "    param = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 500, 2000),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 8),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
        "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
        "        'scale_pos_weight': y_train.value_counts()[0]/y_train.value_counts()[1],\n",
        "        'random_state':42,\n",
        "        'eval_metric':'logloss'\n",
        "    }\n",
        "    model = xgb.XGBClassifier(**param)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    return accuracy_score(y_test, preds)\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(tune_xgb, n_trials=25)\n",
        "best_params_xgb = study.best_trial.params\n",
        "print(\"Best XGBoost params:\", best_params_xgb)\n",
        "\n",
        "# ---------------------------\n",
        "# 11️⃣ Base Models with tuned hyperparameters\n",
        "# ---------------------------\n",
        "xgb_model = xgb.XGBClassifier(**best_params_xgb)\n",
        "lgb_model = lgb.LGBMClassifier(\n",
        "    n_estimators=2000,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.03,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    class_weight='balanced',\n",
        "    random_state=42\n",
        ")\n",
        "cat_model = CatBoostClassifier(\n",
        "    iterations=2000,\n",
        "    depth=6,\n",
        "    learning_rate=0.03,\n",
        "    verbose=0,\n",
        "    class_weights=[y_train.value_counts()[0], y_train.value_counts()[1]],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# ---------------------------\n",
        "# 12️⃣ Feature Selection via XGBoost\n",
        "# ---------------------------\n",
        "selector = SelectFromModel(xgb_model)\n",
        "selector.fit(X_train, y_train)\n",
        "X_train_sel = selector.transform(X_train)\n",
        "X_test_sel = selector.transform(X_test)\n",
        "selected_features = X.columns[selector.get_support()]\n",
        "\n",
        "# ---------------------------\n",
        "# 13️⃣ Stacking Ensemble\n",
        "# ---------------------------\n",
        "estimators = [('xgb', xgb_model), ('lgb', lgb_model), ('cat', cat_model)]\n",
        "stack_model = StackingClassifier(\n",
        "    estimators=estimators,\n",
        "    final_estimator=xgb.XGBClassifier(\n",
        "        n_estimators=500,\n",
        "        max_depth=4,\n",
        "        learning_rate=0.05,\n",
        "        random_state=42,\n",
        "        eval_metric='logloss'\n",
        "    ),\n",
        "    cv=5,\n",
        "    passthrough=True\n",
        ")\n",
        "\n",
        "stack_model.fit(X_train_sel, y_train)\n",
        "\n",
        "# ---------------------------\n",
        "# 14️⃣ Evaluation\n",
        "# ---------------------------\n",
        "y_pred = stack_model.predict(X_test_sel)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"Ultimate Ensemble Accuracy: {acc*100:.2f}%\\n\")\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Feature importance from XGBoost final estimator\n",
        "final_xgb = stack_model.final_estimator_\n",
        "feat_importances = pd.Series(final_xgb.feature_importances_, index=selected_features)\n",
        "top_features = feat_importances.sort_values(ascending=False).head(25)\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.barplot(x=top_features.values, y=top_features.index)\n",
        "plt.title(\"Top 25 Feature Importances - Ultimate Ensemble XGBoost\")\n",
        "plt.show()\n",
        "\n",
        "# ---------------------------\n",
        "# 15️⃣ Real-time Fight Prediction Function\n",
        "# ---------------------------\n",
        "def predict_fight_ultimate(fighter_blue: dict, fighter_red: dict):\n",
        "    fight_data = {}\n",
        "    fight_data['weight_diff'] = fighter_blue['B_Weight'] - fighter_red['R_Weight']\n",
        "    fight_data['height_diff'] = fighter_blue['B_Height'] - fighter_red['R_Height']\n",
        "    fight_data['age_diff'] = fighter_blue['B_Age'] - fighter_red['R_Age']\n",
        "    fight_data['streak_diff'] = fighter_blue['BStreak'] - fighter_red['RStreak']\n",
        "    fight_data['strike_acc_diff'] = fighter_blue.get('B_Strike_Acc',0) - fighter_red.get('R_Strike_Acc',0)\n",
        "    fight_data['td_acc_diff'] = fighter_blue.get('B_TD_Acc',0) - fighter_red.get('R_TD_Acc',0)\n",
        "    fight_data['recent_streak_diff'] = fighter_blue.get('BStreak',0) - fighter_red.get('RStreak',0)\n",
        "\n",
        "    for r in rounds:\n",
        "        for s in stat_types:\n",
        "            b_key = f'B__Round{r}_{s}'\n",
        "            r_key = f'R__Round{r}_{s}'\n",
        "            diff_key = f'{s}_diff_R{r}'\n",
        "            fight_data[diff_key] = fighter_blue.get(b_key,0) - fighter_red.get(r_key,0)\n",
        "\n",
        "    fight_df = pd.DataFrame([fight_data])\n",
        "    fight_df = pd.DataFrame(scaler.transform(fight_df.reindex(columns=X[selected_features].columns, fill_value=0)),\n",
        "                            columns=selected_features)\n",
        "    pred = stack_model.predict(fight_df)[0]\n",
        "    return \"Red Wins\" if pred==1 else \"Blue Wins\"\n"
      ]
    }
  ]
}